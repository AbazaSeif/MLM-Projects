---
title: "R Notebook"
output:
  word_document: default
  pdf_document: default
  html_notebook: default
---

```{r}
dat<-read.csv("../classroom.csv")
attach(dat)
dat$math1st <- mathkind + mathgain
```
##UMM MODEL

```{r, message=FALSE, warning=FALSE}
require(lme4)
require(lmerTest)
umm.1 <- lmer(math1st ~ (1|schoolid/classid), data =dat)
summary(umm.1)
```

$$
MATH1ST_{ijk} = b_0 + \eta_{jk} + \zeta_{k} + \varepsilon_{ijk}
$$
With $\zeta_{k}$ ~ N(0,$\sigma^2_{\zeta}$), $\eta_{jk}$ ~ N(0,$\sigma^2_{\eta}$), and $\varepsilon_{ijk}$ ~ N(0,$\sigma^2_{\varepsilon}$), independent of one another.

####ICC
$$
\sigma^2_{\eta} = 85.46
$$
$$
\sigma^2_{\zeta} = 280.68
$$
$$
\hat{\sigma}^2_{\varepsilon} = 1146.80
$$
$$
ICC = \frac{\sigma^2_{\zeta}}{\sigma^2_{\zeta} + \sigma^2_{\varepsilon}} = \frac{}{364.23 + 1344.5} = 0.207306
$$


##Add school level predictors (HOUSEPOV)
```{r}
lme1<-lmer(math1st~housepov + (1|schoolid/classid),data=dat)
summary(lme1)
```

```{r}
anova(lme1,umm.1)
```

Adding the school-level predictor is statistically significant, and an improvement from the UMM model.

####Report $\sigma^2_{\zeta}$ and $\sigma^2_{\varepsilon}$
$$
\sigma^2_{\eta} = 82.36
$$
$$
\sigma^2_{\zeta} = 250.93
$$
$$
\hat{\sigma}^2_{\varepsilon} = 1146.95
$$

$\sigma^2_{\zeta}$ is reduced from 280.68 to 250.93. $\sigma^2_{\eta}$ is reduced from 85.46 to 82.36. The reduction in school variance is expected. The classroom variance is reduced slightly possibly due to aggregate effect, where classroom has both the school level and classroom effect.

##ADD Class level preds & report if justifed.
```{r}
lme2<-lmer(math1st~housepov + mathknow + mathprep + yearstea + (1|schoolid/classid),data=dat)
summary(lme2)
```

None of the classroom covariates are significant except for household poverty.

####Justified?
```{r}
require(aod)
wald.test(b=fixef(lme2),Sigma=summary(lme2)$vcov,Terms=3:5)
```
The fixed effects using the Wald Test are not significant.

```{r}
rand(lme2)
```
However, the classroom-level random effects are statistically significant.

####Report change to $\sigma^2_{\eta}$
$$
\sigma^2_{\eta} = 94.36
$$
$\sigma^2_{\eta}$ increased from 82.36 to 94.36.

####Report change to $\sigma^2_{\varepsilon}$
$$
\sigma^2_{\varepsilon} = 1136.43
$$
$\sigma^2_{\varepsilon}$ decreased from 1146.95 to 1136.43.

####Hypothesis as to why $\sigma^2_{\varepsilon}$ is reduced.
None of the classroom-level covariates are statistically significant. By adding these variables, it may have increased the uncertainty attributed to the between classroom effect.

##ADD student level preds & report if justifed.
```{r}
lme3<-lmer(math1st~housepov + mathknow + mathprep + yearstea + sex + minority + ses + (1|schoolid/classid),data=dat)
summary(lme3)
```

```{r}
anova(lme2,lme3)
```

The addition of all the student-level predictors is an improvement from the previous model (LRT p-value <0.05).

####Report change in variance components for all levels; why did school level drop?
$$
\sigma^2_{\eta} = 93.89
$$
$$
\sigma^2_{\zeta} = 169.45
$$
$$
\hat{\sigma}^2_{\varepsilon} = 1064.95
$$

$\sigma^2_{\eta}$ drops from 94.36 to 93.89.
$\sigma^2_{\zeta}$ drops from 223.31 to 169.45.
$\sigma}^2_{\varepsilon}$ drops from 1136.43 to 1064.95.


School-level variance drops possibly due to repartitioning. The variance previously attributed to it were explained with the addition of the fixed school variates. 

$$
MATH1ST_{ijk} = b_0 + b_1HOUSEPOV_{k} + b_2MATHKNOW_{jk} + b_3MATHPREP_{jk} + b_4YEARSTEA_{jk} + b_5SEX_{ijk} + b_6MINORITY_{ijk} + b_7SES_{ijk} + \eta_{jk} + \zeta_{k} + \varepsilon_{ijk}
$$
With $\zeta_{k}$ ~ N(0,$\sigma^2_{\zeta}$), $\eta_{jk}$ ~ N(0,$\sigma^2_{\eta}$), and $\varepsilon_{ijk}$ ~ N(0,$\sigma^2_{\varepsilon}$), independent of one another.

##ADD a random slope for each teacher level predictor.

#### MATHKNOW
```{r}
lme4.1<-lmer(math1st~housepov + mathknow + mathprep + yearstea + sex + minority + ses + (0+mathknow|schoolid) + (1|schoolid/classid),data=dat)
summary(lme4.1)
```
```{r}
rand(lme4.1)
```

#### MATHPREP
```{r}
lme4.2<-lmer(math1st~housepov + mathknow + mathprep + yearstea + sex + minority + ses + (0+mathprep|schoolid) + (1|schoolid/classid),data=dat)
summary(lme4.2)
```
```{r}
rand(lme4.2)
```

#### YEARSTEA
```{r}
lme4.3<-lmer(math1st~housepov + mathknow + mathprep + yearstea + sex + minority + ses + (0+yearstea|schoolid) + (1|schoolid/classid),data=dat)
summary(lme4.3)
```
```{r}
rand(lme4.3)
```

##Why not try for a random slope on the housepov effect?

We would not be able to observe the effect of adding a random slope to housepov - there is no level higher up.

##Retry the above, allowing the slopes to be correlated with the random intercepts.

#### MATHKNOW
```{r, message=TRUE, warning=TRUE}
lme4.1.1<-lmer(math1st~housepov + mathknow + mathprep + yearstea + sex + minority + ses + (mathknow|schoolid)+(1|classid),data=dat)
summary(lme4.1.1)
```
```{r}
rand(lme4.1.1)
```

#### MATHPREP
```{r}
lme4.2.1<-lmer(math1st~housepov + mathknow + mathprep + yearstea + sex + minority + ses + (mathprep|schoolid) + (1|classid),data=dat)
summary(lme4.2.1)
```
```{r}
rand(lme4.2.1)
```


#### YEARSTEA
```{r}
lme4.3.1<-lmer(math1st~housepov + mathknow + mathprep + yearstea + sex + minority + ses + (yearstea|schoolid) + (1|classid),data=dat)
summary(lme4.3.1)
```
```{r}
rand(lme4.3.1)
```


###report anything unusual about the variance components



##try to add a random slope for each student level predictor at the classroom level (one by one - not all together)

#### SEX
```{r, message=TRUE, warning=TRUE}
lme5.1<-lmer(math1st~housepov + mathknow + mathprep + yearstea + sex + minority + ses + (0 + sex|classid) + (1|schoolid/classid),data=dat)
summary(lme5.1)
```
```{r}
rand(lme5.1)
```


#### MINORITY
```{r, message=TRUE, warning=TRUE}
lme5.2<-lmer(math1st~housepov + mathknow + mathprep + yearstea + sex + minority + ses + (0 + minority|classid) + (1|schoolid/classid),data=dat)
summary(lme5.2)
```
```{r}
rand(lme5.2)
```


#### SES
```{r, message=TRUE, warning=TRUE}
lme5.3<-lmer(math1st~housepov + mathknow + mathprep + yearstea + sex + minority + ses + (0 + ses|classid) + (1|schoolid/classid),data=dat)
summary(lme5.3)
```
```{r}
rand(lme5.3)
```


##why is it a bad idea to include a class-level variable with random slopes at the classroom level?

We will not be able to observe the varying slopes at the classroom-level, only one level higher (school-level).


##retry the above, allowing the slopes to be correlated with the random intercepts.

#### SEX
```{r, message=TRUE, warning=TRUE}
lme5.1.1<-lmer(math1st~housepov + mathknow + mathprep + yearstea + sex + minority + ses + (sex|classid) + (1|schoolid) ,data=dat)
summary(lme5.1.1)
```
```{r}
rand(lme5.1.1)
```


#### MINORITY
```{r, message=TRUE, warning=TRUE}
lme5.2.1<-lmer(math1st~housepov + mathknow + mathprep + yearstea + sex + minority + ses  + (minority|classid) + (1|schoolid),data=dat)
summary(lme5.2.1)
```
```{r}
rand(lme5.2.1)
```


#### SES
```{r, message=TRUE, warning=TRUE}
lme5.3.1<-lmer(math1st~housepov + mathknow + mathprep + yearstea + sex + minority + ses + (ses|classid) + (1|schoolid),data=dat)
summary(lme5.3.1)
```
```{r}
rand(lme5.3.1)
```


##try to add a random slope for each student level predictor at the school level (one by one - not all together)

####SEX
```{r}
lme6.1<-lmer(math1st~housepov + mathknow + mathprep + yearstea + sex + minority + ses + (0 + sex|schoolid) + (1|schoolid/classid),data=dat)
summary(lme6.1)
```
```{r}
rand(lme6.1)
```


####MINORITY
```{r}
lme6.2<-lmer(math1st~housepov + mathknow + mathprep + yearstea + sex + minority + ses + (0 + minority|schoolid) + (1|schoolid/classid),data=dat)
summary(lme6.2)
```
```{r}
rand(lme6.2)
```


####SES
```{r}
lme6.3<-lmer(math1st~housepov + mathknow + mathprep + yearstea + sex + minority + ses + (0 + ses|schoolid) + (1|schoolid/classid),data=dat)
summary(lme6.3)
```
```{r}
rand(lme6.3)
```


##retry the above, allowing the slopes to be correlated with the random intercepts.

####SEX
```{r}
lme6.1.1<-lmer(math1st~housepov + mathknow + mathprep + yearstea + sex + minority + ses + (sex|schoolid) + (1|classid),data=dat)
summary(lme6.1.1)
```
```{r}
rand(lme6.1.1)
```


####MINORITY
```{r}
lme6.2.1<-lmer(math1st~housepov + mathknow + mathprep + yearstea + sex + minority + ses + (minority|schoolid) + (1|classid),data=dat)
summary(lme6.2.1)
```
```{r}
rand(lme6.2.1)
```


####SES
```{r}
lme6.3.1<-lmer(math1st~housepov + mathknow + mathprep + yearstea + sex + minority + ses + (ses|schoolid) + (1|classid),data=dat)
summary(lme6.3.1)
```
```{r}
rand(lme6.3.1)
```


###report anything unusual about the variance components


##take the two predictors that had "signif." random slopes, in the forms in which they worked (indep. or correlated) 

The two predictors that had statistically significant random slopes are ses random slopes uncorrelated with the school random intercept, and minority random slopes correlated with the school random effect.

####Model:
$$
MATH1ST_{ijk} = b_0 + b_1HOUSEPOV_{k} + b_2MATHKNOW_{jk} + b_3MATHPREP_{jk} + b_4YEARSTEA_{jk} + b_5SEX_{ijk} + b_6MINORITY_{ijk} + b_7SES_{ijk} + \eta_{jk} + \zeta_{0k}  + \zeta_{6k}MINORITY_{ijk} + \zeta_{7k}SES_{ijk} + \varepsilon_{ijk}
$$
With $\zeta_{0k}$ ~ N(0,$\sigma^2_{\zeta_{0}}$), $\zeta_{6k}$ ~ N(0,$\sigma^2_{\zeta_{6}}$), $\zeta_{7k}$ ~ N(0,$\sigma^2_{\zeta_{7}}$),  $\eta_{jk}$ ~ N(0,$\sigma^2_{\eta}$), and $\varepsilon_{ijk}$ ~ N(0,$\sigma^2_{\varepsilon}$), $corr(\zeta_{0k},\zeta_{6k}) = \rho_{\zeta_{0k}\zeta_{6k}}$ and all other pairs of random terms independent of one another.

```{r}
lme.7<-lmer(math1st~housepov + mathknow + mathprep + yearstea + sex + minority + ses + (0+ses|schoolid) + (minority|schoolid) + (1|classid),data=dat)
summary(lme.7)
```


###Justified?

Comparing it to just the model with uncorrelated SES random slopes:
```{r}
anova(lme6.3,lme.7)
```

Comparing it to just the model with correlated MINORITY random slopes:
```{r}
anova(lme6.2.1,lme.7)
```

Both LRT show that having both the random slopes added is an improvement in the model.


##For UCM, write down: V_C, V_S, V_E for the three variance components (simply the estimates).  
```{r}
v_c1=85.46
v_s1=280.68
v_e1=1146.80
```


###Think of them as possibly varying with a covariate, though. For the most complicated (all fixed effects) random INTERCEPTS ONLY model, what are: V_C, V_S, V_E ?

```{r}
v_c2=93.89
v_s2=169.45
v_e2=1064.95
```

###By what fraction did  each decrease with the new predictors in the model?

```{r}
(v_c1-v_c2)/v_c1
(v_s1-v_s2)/v_s1
(v_e1-v_e2)/v_e1

```

*now consider the model with a random slope in ses.  
*what are: V_C, V_S(ses=0), V_E ?   We need to list 'ses=0' here, or we don't know how to use the slope variance

```{r}

fit<-lmer(math1st~housepov + mathknow + mathprep + yearstea + sex + minority + ses + (0 + ses|schoolid) + (1|schoolid/classid),data=dat)
summary(fit)

print(VarCorr(fit), comp=("Variance"))

v_c=VarCorr(fit)[1]$classid.schoolid[1]
v_s=VarCorr(fit)[2]$schoolid[1]
v_ses=VarCorr(fit)[3]$schoolid.1[1]

#V_S(ses=0)
v_c+v_s



```

*what are: V_S(ses=-0.50), V_S(ses=+0.5) ?   

```{r}

#V_S(ses=-0.50)
v_c+v_s+(-.5^2)*v_ses

#V_S(ses=+0.5)
v_c+v_s+(.5^2)*v_ses


```


*now consider the model with a random slope in minority.  
*what are: V_C, V_S(minority=0), V_E ?   We need to list 'minority=0' here, or we don't know how to use the slope variance

```{r}

fit<-lmer(math1st~housepov + mathknow + mathprep + yearstea + sex + minority + ses + (0 + minority|schoolid) + (1|schoolid/classid),data=dat)
summary(fit)

print(VarCorr(fit), comp=("Variance"))

v_c=VarCorr(fit)[1]$classid.schoolid[1]
v_s=VarCorr(fit)[2]$schoolid[1]
v_mino=VarCorr(fit)[3]$schoolid.1[1]

#V_S(minority=0)
v_c+v_s


```


*what are: V_S(minority=0.25), V_S(minority=+0.50), V_S(minority=+0.75) ?   
```{r}
#V_S(minority=0.25)
v_c+v_s+(.25^2)*v_ses

#V_S(minority=0.50)
v_c+v_s+(.5^2)*v_ses

#V_S(minority=0.75)
v_c+v_s+(.75^2)*v_ses


```

*now consider the model with a random slope in ses & minority.
*what are: V_C, V_S(minority=0,ses=0), V_E ?   We need to list 'ses=0, minority=0' here, or we don't know how to use the slope variance

```{r}
fit<-lmer(math1st~housepov + mathknow + mathprep + yearstea + sex + minority + ses + (0 + ses + minority|schoolid) + (1|schoolid/classid),data=dat)

summary(fit)

print(VarCorr(fit), comp=("Variance"))

v_c=VarCorr(fit)[1]$classid.schoolid[1]
v_s=VarCorr(fit)[2]$schoolid[1]
v_ses=VarCorr(fit)[3]$schoolid.1[1]
v_mino=VarCorr(fit)[3]$schoolid.1[4]

#V_S(minority=0,ses=0)
v_c+v_s


```


*what are: V_S(ses=0,minority=0.50), V_S(ses=0.50,minority=0), V_S(ses= 0.50, minority= 0.50) ? 

```{r}
#V_S(ses=0,minority=0.50)
v_c+v_s+.5^2*v_mino

#V_S(ses=0.50,minority=0)
v_c+v_s+.5^2*v_ses

#V_S(ses= 0.50, minority= 0.50)
v_c+v_s+.5^2*v_ses+.5^2*v_mino


```


*In the last model, what is a "likely" (+/- 1 sd) range for \eta_{0jk}

Since \eta_{0jk} has a mean of zero, the "likely" SD range is (-9.2963 , 9.2963)


```{r}

print(VarCorr(fit), comp=("Std.Dev."))

```


*Can we make a similar statement about $\zeta_{0k}$?  
*If so, are you considering either of the two random slope terms, $\zeta_{1k}$ and $\zeta_{2k}$ for ses and minority?

```{r}


```